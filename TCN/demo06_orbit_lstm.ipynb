{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Some Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PyTorch\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader,random_split\n",
    "\n",
    "import math\n",
    "# For data preprocess\n",
    "import numpy as np\n",
    "import csv\n",
    "import os\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "# For plotting\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.pyplot import figure\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "# For txt\n",
    "import sys\n",
    "time_stand = 2024250000000.000\n",
    "import matplotlib\n",
    "# Non-interactive backend, you can't call plt.show() to see the figure interactively\n",
    "# matplotlib.use('Agg') must be placed before import matplotlib.pyplot\n",
    "matplotlib.use('Agg') \n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4320, 6)\n"
     ]
    }
   ],
   "source": [
    "path_SL = 'Data/statlink01_orbit.txt'\n",
    "path_Lunar = 'Data/Lunar_Vector_J2000.txt'\n",
    "path_Sun = 'Data/Sun_Vector_J2000.txt'\n",
    "\n",
    "def datacatcher(path,idx_start,idx_end,line_pass):\n",
    "    f = open(path , encoding='utf-8')\n",
    "    line = f.readline()\n",
    "    list = []\n",
    "    count = 0\n",
    "    while line:\n",
    "        if(count%line_pass == 0):\n",
    "            a = line.split(\" \")            #将数据以空格的方式分隔开\n",
    "            b = a[idx_start:idx_end]              #这就是选择前四行保存下来（如果想保存第2，3行就写成b = a[1,3]）即可\n",
    "            list.append(b)\n",
    "            # list.append('\\n')\n",
    "        line = f.readline()\n",
    "        count = count+1\n",
    "    f.close()\n",
    "    data_array=np.array(list)\n",
    "    return data_array.astype(float)\n",
    "data_SL_raw = datacatcher(path_SL,0,4,4)\n",
    "data_Lunar = datacatcher(path_Lunar,4,7,1)\n",
    "data_Sun = datacatcher(path_Sun,4,7,1)\n",
    "data_time = data_SL_raw[:,:1]-time_stand\n",
    "data_SL = data_SL_raw[:,1:]# 除去时间特征\n",
    "slide_step = 1\n",
    "# Dataset_raw = np.hstack((data_time, data_Sun,data_Lunar, data_SL))#\n",
    "Dataset_raw = np.hstack((data_SL[:-1*slide_step,:],data_SL[1*slide_step:,:]))#\n",
    "print(Dataset_raw.shape)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set Random Seed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "myseed = 5201314##42069\n",
    "def same_seed(seed):\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.manual_seed_all(seed)\n",
    "same_seed(myseed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Some Utilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = {\n",
    "    'n_epochs': 3000,                # maximum number of epochs\n",
    "    'batch_size': 300,               # mini-batch size for dataloader\n",
    "    'optimizer': 'Adam',              # optimization algorithm (optimizer in torch.optim)\n",
    "    'optim_hparas': {                # hyper-parameters for the optimizer (depends on which optimizer you are using)\n",
    "        'lr': 1e-4,                 # learning rate\n",
    "        # 'momentum': 0.9              # momentum\n",
    "        'weight_decay': 1e-5        # weight_decay\n",
    "    },\n",
    "    'early_stop': 1000,               # early stopping epochs (the number epochs since your model's last improvement)\n",
    "    'save_path': 'models/model.pth' , # your model will be saved here\n",
    "    'fig_path': 'fig/',\n",
    "    'fig_type': 'png',\n",
    "    'window_len':100*2,                   # T = 100\n",
    "    'window_step':1,\n",
    "    'future':100\n",
    "}\n",
    "def get_device():\n",
    "    ''' Get device (if GPU is available, use GPU) '''\n",
    "    return 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "def train_valid_split(data_set,valid_ratio,seed):\n",
    "    # data_set = data_set[:2000]  \n",
    "    # test_data = data_set[1400:]   #600\n",
    "    # train_data = data_set[:1200] #1200\n",
    "    # valid_data = data_set[1200:1400] #200\n",
    "    test_data = data_set[3000:]   # 1320\n",
    "    train_data = data_set[:2600] # 2600\n",
    "    valid_data = data_set[2600:3000] # 400\n",
    "    print(f'size of test_data is {test_data.shape}')\n",
    "    print(f'size of train_data is {train_data.shape}')\n",
    "    print(f'size of valid_data is {valid_data.shape}')\n",
    "    return np.array(train_data),np.array(valid_data),np.array(test_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "size of test_data is (1320, 6)\n",
      "size of train_data is (2600, 6)\n",
      "size of valid_data is (400, 6)\n"
     ]
    }
   ],
   "source": [
    "# 对训练集和测试集进行归一化\n",
    "m_x = MinMaxScaler()\n",
    "m_y = MinMaxScaler()\n",
    "m_z = MinMaxScaler()\n",
    "\n",
    "# 前三列为Input,归一化就好，不用保存参数\n",
    "Dataset_raw[:,0] = m_x.fit_transform(Dataset_raw[:,0].reshape(-1, 1)).flatten() #注意fit_transform() 和 transform()的区别\n",
    "Dataset_raw[:,1] = m_y.fit_transform(Dataset_raw[:,1].reshape(-1, 1)).flatten() #注意fit_transform() 和 transform()的区别\n",
    "Dataset_raw[:,2] = m_z.fit_transform(Dataset_raw[:,2].reshape(-1, 1)).flatten() #注意fit_transform() 和 transform()的区别\n",
    "# 后三列为Output,归一化还需保存参数，反归一化再用\n",
    "Dataset_raw[:,3] = m_x.fit_transform(Dataset_raw[:,3].reshape(-1, 1)).flatten() #注意fit_transform() 和 transform()的区别\n",
    "Dataset_raw[:,4] = m_y.fit_transform(Dataset_raw[:,4].reshape(-1, 1)).flatten() #注意fit_transform() 和 transform()的区别\n",
    "Dataset_raw[:,5] = m_z.fit_transform(Dataset_raw[:,5].reshape(-1, 1)).flatten() #注意fit_transform() 和 transform()的区别\n",
    "# 分解数据\n",
    "valid_ratio = 0.1\n",
    "train_data, valid_data, test_data = train_valid_split(Dataset_raw,valid_ratio,myseed)\n",
    "train_data = train_data.astype(float)\n",
    "valid_data = valid_data.astype(float)\n",
    "test_data = test_data.astype(float)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Set Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class OrbitDataset(Dataset):\n",
    "    # input:数据路径；模式（默认为train）；特征选择\n",
    "    def __init__(self,\n",
    "                 data,\n",
    "                 mode='train'):\n",
    "        # Determine the mode\n",
    "        self.mode = mode\n",
    "        # 检查数据类型\n",
    "        data = np.array(data)  # Convert to numpy array if not already\n",
    "        print(data.dtype)  # 查看数据类型\n",
    "        if mode == 'test':\n",
    "            # Testing data\n",
    "            # data: 321 x 10 \n",
    "            data = data[:, 0]\n",
    "            self.data = torch.FloatTensor(np.array(data)).unsqueeze(1)# 转化成张量\n",
    "        else:\n",
    "            target = data[:, 0+3]\n",
    "            data = data[:, 0]\n",
    "            # target = data[:, -3:]\n",
    "            # data = data[:, :3]\n",
    "            \n",
    "            # Convert data into PyTorch tensors\n",
    "            self.data = torch.FloatTensor(np.array(data)).unsqueeze(1)\n",
    "            self.target = torch.FloatTensor(np.array(target)).unsqueeze(1)\n",
    "        # self.data[:, 0] = self.data[:, 0]\n",
    "        # 数据归一化\n",
    "        # self.data[:, 1:] = \\\n",
    "        #     (self.data[:, 1:] - self.data[:, 1:].mean(dim=0, keepdim=True)) \\\n",
    "        #     / self.data[:, 1:].std(dim=0, keepdim=True)\n",
    "\n",
    "        # self.dim = self.data.shape[1]# 选取的是第二维度\n",
    "        self.dim = 1# 选取的是第二维度\n",
    "        print('Finished reading the {} set of Orbit Dataset ({} samples found, each dim = {})'\n",
    "              .format(mode, len(self.data), self.dim))\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        # Returns one sample at a time\n",
    "        if self.mode in ['train', 'dev']:\n",
    "            # For training\n",
    "            return self.data[index], self.target[index]\n",
    "        else:\n",
    "            # For testing (no target)\n",
    "            return self.data[index]\n",
    "\n",
    "    def __len__(self):\n",
    "        # Returns the size of the dataset\n",
    "        return len(self.data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prep_dataloader(data, mode, congfig, n_jobs=0):\n",
    "    ''' Generates a dataset, then is put into a dataloader. '''\n",
    "    dataset = OrbitDataset(data, mode=mode)  # Construct dataset\n",
    "    batch_x = list()\n",
    "    batch_y = list()\n",
    "    window_len = congfig['window_len']\n",
    "    for end in range(len(dataset.data) - window_len, -1, -1*congfig['window_step']):\n",
    "        batch_x.append(dataset.data[end:end+window_len])\n",
    "        if mode in ('train', 'dev'):\n",
    "            batch_y.append(dataset.target[end:end+window_len])\n",
    "        else:\n",
    "            batch_y = batch_x\n",
    "\n",
    "    # batch_x的shape是(-, window_len, 1) \n",
    "\n",
    "    from torch.nn.utils.rnn import pad_sequence\n",
    "    batch_x = pad_sequence(batch_x)\n",
    "    batch_y = pad_sequence(batch_y)\n",
    " \n",
    "    # batch_x的shape是(window_len, -, 1)   \n",
    "    batch_x,batch_y = batch_x.permute(1, 0, 2),batch_y.permute(1, 0, 2)\n",
    "    # print(f'shape of batch_x:{batch_x.shape}')\n",
    "    # print(f'shape of batch_y:{batch_y.shape}')\n",
    "    # return batch_x.permute(1, 0, 2),batch_y.permute(1, 0, 2)\n",
    "    return batch_x.squeeze(2),batch_y.squeeze(2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTM_Model(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(LSTM_Model, self).__init__()\n",
    "        # define the dim\n",
    "        self.input_dim = 1\n",
    "        self.hid_dim = 51\n",
    "        self.output_dim = 1\n",
    "        # set the model parts\n",
    "        self.lstm1 = nn.LSTMCell(self.input_dim, self.hid_dim)\n",
    "        self.lstm2 = nn.LSTMCell(self.hid_dim, self.hid_dim)\n",
    "        self.FC = nn.Sequential(\n",
    "            nn.Linear(self.hid_dim, 16),\n",
    "            nn.Sigmoid(),\n",
    "            nn.Linear(16, 4),\n",
    "            nn.Sigmoid(),\n",
    "            nn.Linear(4, self.output_dim),\n",
    "        )  # FC\n",
    "        self.criterion = nn.MSELoss(reduction='mean')\n",
    "    def forward(self, input, future = 0):\n",
    "        outputs = []\n",
    "        # c:记忆元里面存放的值\n",
    "        # h:前一个时间点的输出\n",
    "        h_t = torch.zeros(input.size(0), self.hid_dim , dtype=torch.float)\n",
    "        c_t = torch.zeros(input.size(0), self.hid_dim , dtype=torch.float)\n",
    "        h_t2 = torch.zeros(input.size(0), self.hid_dim, dtype=torch.float)\n",
    "        c_t2 = torch.zeros(input.size(0), self.hid_dim, dtype=torch.float)\n",
    "\n",
    "        h_t = h_t.to(device)\n",
    "        c_t = c_t.to(device)\n",
    "        h_t2 = h_t2.to(device)\n",
    "        c_t2 = c_t2.to(device)\n",
    "\n",
    "        for i, input_t in enumerate(input.chunk(input.size(1), dim=1)):\n",
    "            h_t, c_t = self.lstm1(input_t, (h_t, c_t))\n",
    "            h_t2, c_t2 = self.lstm2(h_t, (h_t2, c_t2))\n",
    "            output = self.FC(h_t2)  # output.shape:[batch,1]\n",
    "            outputs += [output] # outputs.shape:[[batch,1],...[batch,1]], list composed of n [batch,1],\n",
    "        for i in range(future):# if we should predict the future\n",
    "            h_t, c_t = self.lstm1(output, (h_t, c_t)) \n",
    "            h_t2, c_t2 = self.lstm2(h_t, (h_t2, c_t2))\n",
    "            output = self.FC(h_t2) # output.shape:[batch,1]\n",
    "            outputs += [output]  # outputs.shape:[[batch,1],...[batch,1]], list composed of n [batch,1],\n",
    "        outputs = torch.stack(outputs, 1).squeeze(2) # shape after stack:[batch, n, 1], shape after squeeze: [batch,n]\n",
    "        return outputs\n",
    "    def cal_loss(self, pred, target):\n",
    "        return self.criterion(pred, target)\n",
    "    def r2_loss(self, pred, target):\n",
    "        target_mean = torch.mean(target)\n",
    "        ss_tot = torch.sum((target - target_mean) ** 2)\n",
    "        ss_res = torch.sum((target - pred) ** 2)\n",
    "        r2 = 1 - ss_res / ss_tot\n",
    "        return r2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## --Train/Dev/Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training\n",
    "def train(tr_set_x,tr_set_y, dv_set_x,dv_set_y,  model, config, device):\n",
    "    n_epochs = config['n_epochs']  # Maximum number of epochs\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=config['optim_hparas']['lr'], weight_decay=config['optim_hparas']['weight_decay'])\n",
    "    min_mse = math.inf # 初始设置为无穷大math.inf也行\n",
    "    loss_record = {'train': [], 'dev': []}      # for recording training loss\n",
    "    early_stop_cnt = 0\n",
    "    epoch = 0\n",
    "\n",
    "    while epoch < n_epochs:\n",
    "        model.train()                           # set model to training mode\n",
    "        x,y = tr_set_x,tr_set_y\n",
    "        # y = y.squeeze(2)\n",
    "        optimizer.zero_grad()               # set gradient to zero\n",
    "        x, y= x.to(device), y.to(device)    # move data to device (cpu/cuda)\n",
    "        # model.hidden_cell = (torch.zeros(1, 1, model.hidden_layer_size),\n",
    "        #                     torch.zeros(1, 1, model.hidden_layer_size))\n",
    "        pred = model(x)                     # forward pass (compute output)\n",
    "        # pred, hidden_prev = model(x, hidden_prev)\n",
    "        # hidden_prev = hidden_prev.detach()\n",
    "        # print(f'shape of pred:{pred.shape}')\n",
    "        # print(f'shape of y:{y.shape}')\n",
    "        train_r2score = model.r2_loss(pred, y)\n",
    "        mse_loss = model.cal_loss(pred, y)  # compute loss\n",
    "        mse_loss.backward()                 # compute gradient (backpropagation)\n",
    "        optimizer.step()                    # update model with optimizer\n",
    "        loss_record['train'].append(mse_loss.detach().cpu().item())# 记录train的Loss,放在字典里面\n",
    "        mean_train_loss = sum(loss_record['train'])/len(loss_record['train'])# 记录训练的loss\n",
    "        # After each epoch, test your model on the validation (development) set.\n",
    "        dev_mse,dev_r2score = dev(dv_set_x,dv_set_y, model, device)\n",
    "        if dev_mse < min_mse:\n",
    "            # Save model if your model improved\n",
    "            min_mse = dev_mse\n",
    "            print('Saving model (Epoch = {:4d}/{:4d}, train_loss = {:.4f}, dev_loss = {:.4f})\\n train_r2score = {:.4f},dev_r2score={:.4f}'\n",
    "                .format(epoch + 1,config['n_epochs'], mean_train_loss, min_mse,train_r2score,dev_r2score))\n",
    "            torch.save(model.state_dict(), config['save_path'])  # Save model to specified path\n",
    "            early_stop_cnt = 0\n",
    "        else:\n",
    "            # 如果模型没有优化，就记录加一，否则清零\n",
    "            early_stop_cnt += 1\n",
    "\n",
    "        epoch += 1\n",
    "        torch.cuda.empty_cache()\n",
    "        loss_record['dev'].append(dev_mse)\n",
    "        if early_stop_cnt > config['early_stop']:\n",
    "            # Stop training if your model stops improving for \"config['early_stop']\" epochs.\n",
    "            break\n",
    "\n",
    "    print('Finished training after {} epochs'.format(epoch))\n",
    "    return pred,min_mse, loss_record\n",
    "\n",
    "# Validation\n",
    "def dev(dv_set_x,dv_set_y, model, device):\n",
    "    model.eval()                                # set model to evalutation mode\n",
    "    total_loss = 0\n",
    "    # for x, y in zip(dv_set_x,dv_set_y):                         # iterate through the dataloader\n",
    "    x, y = dv_set_x,dv_set_y\n",
    "    x, y = x.to(device), y.to(device)      # move data to device (cpu/cuda)\n",
    "    with torch.no_grad():                   # disable gradient calculation\n",
    "        # model.hidden_cell = (torch.zeros(1, 1, model.hidden_layer_size),\n",
    "        #                     torch.zeros(1, 1, model.hidden_layer_size))\n",
    "        pred = model(x)\n",
    "        dev_r2score = model.r2_loss(pred, y)\n",
    "        mse_loss = model.cal_loss(pred, y)  # compute loss\n",
    "    total_loss += mse_loss.detach().cpu().item() * len(x)  # accumulate loss\n",
    "    total_loss = total_loss / len(dv_set_x)              # compute averaged loss\n",
    "\n",
    "    return total_loss,dev_r2score\n",
    "def save_pred(preds, file):\n",
    "    ''' Save predictions to specified file '''\n",
    "    print('Saving results to {}'.format(file))\n",
    "    with open(file, 'w') as fp:\n",
    "        writer = csv.writer(fp)\n",
    "        writer.writerow(['id', 'tested_positive'])\n",
    "        for i, p in enumerate(preds):\n",
    "            writer.writerow([i, p])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data and model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "float64\n",
      "Finished reading the train set of Orbit Dataset (2600 samples found, each dim = 1)\n",
      "float64\n",
      "Finished reading the dev set of Orbit Dataset (400 samples found, each dim = 1)\n",
      "float64\n",
      "Finished reading the test set of Orbit Dataset (1320 samples found, each dim = 1)\n",
      "cuda\n"
     ]
    }
   ],
   "source": [
    "tr_set_x,tr_set_y = prep_dataloader(train_data, 'train', config)\n",
    "dv_set_x,dv_set_y = prep_dataloader(valid_data, 'dev', config)\n",
    "tt_set_x,tt_set_y = prep_dataloader(test_data, 'test', config)\n",
    "# print(tr_set.dataset.dim)\n",
    "device = get_device()                 # get the current available device ('cpu' or 'cuda')\n",
    "print(device)\n",
    "os.makedirs('models', exist_ok=True)  # The trained model will be saved to ./models/\n",
    "model = LSTM_Model().float().to(device)  # Construct model and move to device\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## StartTrain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\PythonEnviroment\\envs\\pytorch\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[12], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtr_set_x\u001b[49m\u001b[43m,\u001b[49m\u001b[43mtr_set_y\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdv_set_x\u001b[49m\u001b[43m,\u001b[49m\u001b[43mdv_set_y\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[10], line 4\u001b[0m, in \u001b[0;36mtrain\u001b[1;34m(tr_set_x, tr_set_y, dv_set_x, dv_set_y, model, config, device)\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mtrain\u001b[39m(tr_set_x,tr_set_y, dv_set_x,dv_set_y,  model, config, device):\n\u001b[0;32m      3\u001b[0m     n_epochs \u001b[38;5;241m=\u001b[39m config[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mn_epochs\u001b[39m\u001b[38;5;124m'\u001b[39m]  \u001b[38;5;66;03m# Maximum number of epochs\u001b[39;00m\n\u001b[1;32m----> 4\u001b[0m     optimizer \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptim\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mAdam\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparameters\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43moptim_hparas\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mlr\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweight_decay\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43moptim_hparas\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mweight_decay\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      5\u001b[0m     min_mse \u001b[38;5;241m=\u001b[39m math\u001b[38;5;241m.\u001b[39minf \u001b[38;5;66;03m# 初始设置为无穷大math.inf也行\u001b[39;00m\n\u001b[0;32m      6\u001b[0m     loss_record \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m'\u001b[39m: [], \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdev\u001b[39m\u001b[38;5;124m'\u001b[39m: []}      \u001b[38;5;66;03m# for recording training loss\u001b[39;00m\n",
      "File \u001b[1;32md:\\PythonEnviroment\\envs\\pytorch\\Lib\\site-packages\\torch\\optim\\adam.py:45\u001b[0m, in \u001b[0;36mAdam.__init__\u001b[1;34m(self, params, lr, betas, eps, weight_decay, amsgrad, foreach, maximize, capturable, differentiable, fused)\u001b[0m\n\u001b[0;32m     39\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInvalid weight_decay value: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mweight_decay\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     41\u001b[0m defaults \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mdict\u001b[39m(lr\u001b[38;5;241m=\u001b[39mlr, betas\u001b[38;5;241m=\u001b[39mbetas, eps\u001b[38;5;241m=\u001b[39meps,\n\u001b[0;32m     42\u001b[0m                 weight_decay\u001b[38;5;241m=\u001b[39mweight_decay, amsgrad\u001b[38;5;241m=\u001b[39mamsgrad,\n\u001b[0;32m     43\u001b[0m                 maximize\u001b[38;5;241m=\u001b[39mmaximize, foreach\u001b[38;5;241m=\u001b[39mforeach, capturable\u001b[38;5;241m=\u001b[39mcapturable,\n\u001b[0;32m     44\u001b[0m                 differentiable\u001b[38;5;241m=\u001b[39mdifferentiable, fused\u001b[38;5;241m=\u001b[39mfused)\n\u001b[1;32m---> 45\u001b[0m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__init__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdefaults\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     47\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m fused:\n\u001b[0;32m     48\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m differentiable:\n",
      "File \u001b[1;32md:\\PythonEnviroment\\envs\\pytorch\\Lib\\site-packages\\torch\\optim\\optimizer.py:266\u001b[0m, in \u001b[0;36mOptimizer.__init__\u001b[1;34m(self, params, defaults)\u001b[0m\n\u001b[0;32m    263\u001b[0m     param_groups \u001b[38;5;241m=\u001b[39m [{\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mparams\u001b[39m\u001b[38;5;124m'\u001b[39m: param_groups}]\n\u001b[0;32m    265\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m param_group \u001b[38;5;129;01min\u001b[39;00m param_groups:\n\u001b[1;32m--> 266\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43madd_param_group\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcast\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mdict\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparam_group\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    268\u001b[0m \u001b[38;5;66;03m# Allows _cuda_graph_capture_health_check to rig a poor man's TORCH_WARN_ONCE in python,\u001b[39;00m\n\u001b[0;32m    269\u001b[0m \u001b[38;5;66;03m# which I don't think exists\u001b[39;00m\n\u001b[0;32m    270\u001b[0m \u001b[38;5;66;03m# https://github.com/pytorch/pytorch/issues/72948\u001b[39;00m\n\u001b[0;32m    271\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_warned_capturable_if_run_uncaptured \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[1;32md:\\PythonEnviroment\\envs\\pytorch\\Lib\\site-packages\\torch\\_compile.py:22\u001b[0m, in \u001b[0;36m_disable_dynamo.<locals>.inner\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     20\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(fn)\n\u001b[0;32m     21\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21minner\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m---> 22\u001b[0m     \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_dynamo\u001b[39;00m\n\u001b[0;32m     24\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m torch\u001b[38;5;241m.\u001b[39m_dynamo\u001b[38;5;241m.\u001b[39mdisable(fn, recursive)(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32md:\\PythonEnviroment\\envs\\pytorch\\Lib\\site-packages\\torch\\_dynamo\\__init__.py:5\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbackends\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mregistry\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m list_backends, register_backend\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mconvert_frame\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m replay\n\u001b[1;32m----> 5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdecorators\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[0;32m      6\u001b[0m     allow_in_graph,\n\u001b[0;32m      7\u001b[0m     assume_constant_result,\n\u001b[0;32m      8\u001b[0m     disable,\n\u001b[0;32m      9\u001b[0m     disallow_in_graph,\n\u001b[0;32m     10\u001b[0m     forbid_in_graph,\n\u001b[0;32m     11\u001b[0m     graph_break,\n\u001b[0;32m     12\u001b[0m     mark_dynamic,\n\u001b[0;32m     13\u001b[0m     mark_static,\n\u001b[0;32m     14\u001b[0m     mark_static_address,\n\u001b[0;32m     15\u001b[0m     maybe_mark_dynamic,\n\u001b[0;32m     16\u001b[0m     run,\n\u001b[0;32m     17\u001b[0m )\n\u001b[0;32m     18\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01meval_frame\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[0;32m     19\u001b[0m     explain,\n\u001b[0;32m     20\u001b[0m     export,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     25\u001b[0m     reset_code,\n\u001b[0;32m     26\u001b[0m )\n\u001b[0;32m     27\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mexternal_utils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m is_compiling\n",
      "File \u001b[1;32md:\\PythonEnviroment\\envs\\pytorch\\Lib\\site-packages\\torch\\_dynamo\\decorators.py:141\u001b[0m\n\u001b[0;32m    119\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    120\u001b[0m \u001b[38;5;124;03m    Customize which functions TorchDynamo will exclude in the generated\u001b[39;00m\n\u001b[0;32m    121\u001b[0m \u001b[38;5;124;03m    graph and force a graph break on.\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    136\u001b[0m \u001b[38;5;124;03m    single `torch.add()` op.\u001b[39;00m\n\u001b[0;32m    137\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m    138\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _disallow_in_graph_helper(throw_if_not_allowed\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)(fn)\n\u001b[1;32m--> 141\u001b[0m \u001b[38;5;129;43m@_disallow_in_graph_helper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mthrow_if_not_allowed\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[0;32m    142\u001b[0m \u001b[38;5;28;43;01mdef\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;21;43mgraph_break\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[0;32m    143\u001b[0m \u001b[38;5;250;43m    \u001b[39;49m\u001b[38;5;124;43;03m\"\"\"Force a graph break\"\"\"\u001b[39;49;00m\n\u001b[0;32m    144\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mpass\u001b[39;49;00m\n",
      "File \u001b[1;32md:\\PythonEnviroment\\envs\\pytorch\\Lib\\site-packages\\torch\\_dynamo\\decorators.py:110\u001b[0m, in \u001b[0;36m_disallow_in_graph_helper.<locals>.inner\u001b[1;34m(fn)\u001b[0m\n\u001b[0;32m    105\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m throw_if_not_allowed \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m allowed_functions\u001b[38;5;241m.\u001b[39mis_allowed(fn):\n\u001b[0;32m    106\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m IncorrectUsage(\n\u001b[0;32m    107\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdisallow_in_graph is expected to be used on an already allowed callable (like torch.* ops). \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    108\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAllowed callables means callables that TorchDynamo puts as-is in the extracted graph.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    109\u001b[0m     )\n\u001b[1;32m--> 110\u001b[0m \u001b[43mallowed_functions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_allowed_function_ids\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mremove\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mid\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mfn\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    111\u001b[0m allowed_functions\u001b[38;5;241m.\u001b[39m_disallowed_function_ids\u001b[38;5;241m.\u001b[39madd(\u001b[38;5;28mid\u001b[39m(fn))\n\u001b[0;32m    112\u001b[0m allowed_functions\u001b[38;5;241m.\u001b[39m_allowed_user_defined_function_ids\u001b[38;5;241m.\u001b[39mremove(\u001b[38;5;28mid\u001b[39m(fn))\n",
      "File \u001b[1;32md:\\PythonEnviroment\\envs\\pytorch\\Lib\\site-packages\\torch\\_dynamo\\allowed_functions.py:81\u001b[0m, in \u001b[0;36mmake_function_id_set.<locals>.FunctionIdSet.remove\u001b[1;34m(self, idx)\u001b[0m\n\u001b[0;32m     80\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mremove\u001b[39m(\u001b[38;5;28mself\u001b[39m, idx: \u001b[38;5;28mint\u001b[39m):\n\u001b[1;32m---> 81\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[0;32m     82\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfunction_ids\u001b[38;5;241m.\u001b[39mremove(idx)\n",
      "File \u001b[1;32md:\\PythonEnviroment\\envs\\pytorch\\Lib\\site-packages\\torch\\_dynamo\\allowed_functions.py:63\u001b[0m, in \u001b[0;36mmake_function_id_set.<locals>.FunctionIdSet.__call__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     61\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m     62\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfunction_ids \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m---> 63\u001b[0m         value \u001b[38;5;241m=\u001b[39m \u001b[43mlazy_initializer\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     64\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(value, \u001b[38;5;28mdict\u001b[39m):\n\u001b[0;32m     65\u001b[0m             \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfunction_ids \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m(value\u001b[38;5;241m.\u001b[39mkeys())\n",
      "File \u001b[1;32md:\\PythonEnviroment\\envs\\pytorch\\Lib\\site-packages\\torch\\_dynamo\\allowed_functions.py:226\u001b[0m, in \u001b[0;36m_allowed_function_ids\u001b[1;34m()\u001b[0m\n\u001b[0;32m    223\u001b[0m             \u001b[38;5;28;01melif\u001b[39;00m inspect\u001b[38;5;241m.\u001b[39mgetmodule(obj) \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_safe_constant(obj):\n\u001b[0;32m    224\u001b[0m                 torch_object_ids[\u001b[38;5;28mid\u001b[39m(obj)] \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmodule\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m--> 226\u001b[0m \u001b[43m_find_torch_objects\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtorch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    227\u001b[0m _find_torch_objects(math)\n\u001b[0;32m    229\u001b[0m \u001b[38;5;66;03m# torch.Tensor.{fn}\u001b[39;00m\n",
      "File \u001b[1;32md:\\PythonEnviroment\\envs\\pytorch\\Lib\\site-packages\\torch\\_dynamo\\allowed_functions.py:220\u001b[0m, in \u001b[0;36m_allowed_function_ids.<locals>._find_torch_objects\u001b[1;34m(module)\u001b[0m\n\u001b[0;32m    216\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m obj\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;241m.\u001b[39mstartswith(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtorch.\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m _is_allowed_module_prefix(\n\u001b[0;32m    217\u001b[0m         obj\n\u001b[0;32m    218\u001b[0m     ):\n\u001b[0;32m    219\u001b[0m         torch_object_ids[\u001b[38;5;28mid\u001b[39m(obj)] \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmodule\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m--> 220\u001b[0m         \u001b[43m_find_torch_objects\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobj\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    221\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m _is_allowed_module_prefix(obj):\n\u001b[0;32m    222\u001b[0m     torch_object_ids[\u001b[38;5;28mid\u001b[39m(obj)] \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmodule\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n",
      "File \u001b[1;32md:\\PythonEnviroment\\envs\\pytorch\\Lib\\site-packages\\torch\\_dynamo\\allowed_functions.py:220\u001b[0m, in \u001b[0;36m_allowed_function_ids.<locals>._find_torch_objects\u001b[1;34m(module)\u001b[0m\n\u001b[0;32m    216\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m obj\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;241m.\u001b[39mstartswith(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtorch.\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m _is_allowed_module_prefix(\n\u001b[0;32m    217\u001b[0m         obj\n\u001b[0;32m    218\u001b[0m     ):\n\u001b[0;32m    219\u001b[0m         torch_object_ids[\u001b[38;5;28mid\u001b[39m(obj)] \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmodule\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m--> 220\u001b[0m         \u001b[43m_find_torch_objects\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobj\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    221\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m _is_allowed_module_prefix(obj):\n\u001b[0;32m    222\u001b[0m     torch_object_ids[\u001b[38;5;28mid\u001b[39m(obj)] \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmodule\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n",
      "    \u001b[1;31m[... skipping similar frames: _allowed_function_ids.<locals>._find_torch_objects at line 220 (12 times)]\u001b[0m\n",
      "File \u001b[1;32md:\\PythonEnviroment\\envs\\pytorch\\Lib\\site-packages\\torch\\_dynamo\\allowed_functions.py:220\u001b[0m, in \u001b[0;36m_allowed_function_ids.<locals>._find_torch_objects\u001b[1;34m(module)\u001b[0m\n\u001b[0;32m    216\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m obj\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;241m.\u001b[39mstartswith(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtorch.\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m _is_allowed_module_prefix(\n\u001b[0;32m    217\u001b[0m         obj\n\u001b[0;32m    218\u001b[0m     ):\n\u001b[0;32m    219\u001b[0m         torch_object_ids[\u001b[38;5;28mid\u001b[39m(obj)] \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmodule\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m--> 220\u001b[0m         \u001b[43m_find_torch_objects\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobj\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    221\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m _is_allowed_module_prefix(obj):\n\u001b[0;32m    222\u001b[0m     torch_object_ids[\u001b[38;5;28mid\u001b[39m(obj)] \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmodule\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n",
      "File \u001b[1;32md:\\PythonEnviroment\\envs\\pytorch\\Lib\\site-packages\\torch\\_dynamo\\allowed_functions.py:187\u001b[0m, in \u001b[0;36m_allowed_function_ids.<locals>._find_torch_objects\u001b[1;34m(module)\u001b[0m\n\u001b[0;32m    186\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_find_torch_objects\u001b[39m(module):\n\u001b[1;32m--> 187\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28many\u001b[39m(\n\u001b[0;32m    188\u001b[0m         module\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;241m.\u001b[39mstartswith(mod_name)\n\u001b[0;32m    189\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m mod_name \u001b[38;5;129;01min\u001b[39;00m config\u001b[38;5;241m.\u001b[39mallowed_functions_module_string_ignorelist\n\u001b[0;32m    190\u001b[0m     ):\n\u001b[0;32m    191\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[0;32m    192\u001b[0m     torch_object_ids[\u001b[38;5;28mid\u001b[39m(module)] \u001b[38;5;241m=\u001b[39m module\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\n",
      "File \u001b[1;32md:\\PythonEnviroment\\envs\\pytorch\\Lib\\site-packages\\torch\\_dynamo\\allowed_functions.py:187\u001b[0m, in \u001b[0;36m<genexpr>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    186\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_find_torch_objects\u001b[39m(module):\n\u001b[1;32m--> 187\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28many\u001b[39m(\n\u001b[0;32m    188\u001b[0m         module\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;241m.\u001b[39mstartswith(mod_name)\n\u001b[0;32m    189\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m mod_name \u001b[38;5;129;01min\u001b[39;00m config\u001b[38;5;241m.\u001b[39mallowed_functions_module_string_ignorelist\n\u001b[0;32m    190\u001b[0m     ):\n\u001b[0;32m    191\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[0;32m    192\u001b[0m     torch_object_ids[\u001b[38;5;28mid\u001b[39m(module)] \u001b[38;5;241m=\u001b[39m module\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "train(tr_set_x,tr_set_y, dv_set_x,dv_set_y,  model, config, device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## StartPredict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([200])\n",
      "the size of input is torch.Size([1, 200])\n",
      "Saving results to pred.csv\n"
     ]
    }
   ],
   "source": [
    "# del model\n",
    "# # 删除当前的 model 对象。这样做是为了释放内存\n",
    "# model = LSTM_Model().to(device)\n",
    "# ckpt = torch.load(config['save_path'], map_location='cpu')  # Load your best model\n",
    "# model.load_state_dict(ckpt)\n",
    "input = tt_set_x[0,:].to(device)\n",
    "print(input.shape)\n",
    "input = input.unsqueeze(0)\n",
    "\n",
    "# begin to predict, no need to track gradient here\n",
    "with torch.no_grad():\n",
    "    future = config['future']\n",
    "    preds = model(input, future=future)\n",
    "    preds = preds.detach().cpu()\n",
    "    preds = preds.numpy()\n",
    "preds = np.array(preds)\n",
    "print(f'the size of input is {input.size()}')\n",
    "# print(f'the size of input is {preds.size()}')\n",
    "# 反归一化\n",
    "preds = m_x.inverse_transform(preds[0,:].reshape(-1, 1)).flatten()\n",
    "save_pred(preds, 'pred.csv')         # save prediction file to pred.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prediction Plotting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(300,)\n",
      "(300,)\n",
      "torch.Size([1121, 200])\n"
     ]
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "# draw the result\n",
    "# xx = m_x.inverse_transform(tt_set_x[:1,:].permute(1, 0).cpu().numpy()[:config['window_len'],0].reshape(-1, 1)).flatten() #反归一化\n",
    "xx = m_x.inverse_transform(Dataset_raw[3000:3300,0].reshape(-1, 1)).flatten()\n",
    "error = xx - preds\n",
    "print(preds.shape)\n",
    "print(xx.shape)\n",
    "print(tt_set_x.shape)\n",
    "\n",
    "\n",
    "# 直接指定保存的文件夹路径\n",
    "folder = config['fig_path']  # 请替换为你的文件夹路径\n",
    "fig_type = config['fig_type']\n",
    "# draw predict\n",
    "plt.figure(figsize=(30,10))\n",
    "plt.title('Predict future values for time sequences\\n(Dashlines are predicted values)', fontsize=30)\n",
    "plt.xlabel('time', fontsize=24)\n",
    "plt.ylabel('prediction', fontsize=24)\n",
    "plt.xticks(fontsize=24)\n",
    "plt.yticks(fontsize=24)\n",
    "def draw(yi, color,label):\n",
    "    plt.plot(np.arange(input.size(1)), yi[:input.size(1)], color, linewidth = 3.0, label=label)\n",
    "    plt.plot(np.arange(input.size(1), input.size(1) + future), yi[input.size(1):], color + ':', linewidth = 3.0)\n",
    "draw(preds, 'r','pred')\n",
    "# plt.plot(np.array(list(range(0,len(xx)))),xx, 'g', linewidth = 2.0)\n",
    "draw(xx, 'b','true')\n",
    "plt.legend(fontsize=24)\n",
    "plt.grid(True)\n",
    "\n",
    "pdf_filename = f\"{folder}predict_{datetime.now().strftime('%Y-%m-%d_%H-%M-%S')}.{fig_type}\"\n",
    "plt.savefig(pdf_filename)\n",
    "plt.close()\n",
    "# draw err\n",
    "plt.figure(figsize=(30,10))\n",
    "plt.title('error\\n(Dashlines are predicted values)', fontsize=30)\n",
    "plt.xlabel('time', fontsize=24)\n",
    "plt.ylabel('error', fontsize=24)\n",
    "plt.xticks(fontsize=24)\n",
    "plt.yticks(fontsize=24)\n",
    "def draw(yi, color,label):\n",
    "    plt.plot(np.arange(input.size(1)), yi[:input.size(1)], color, linewidth = 3.0, label=label)\n",
    "    plt.plot(np.arange(input.size(1), input.size(1) + future), yi[input.size(1):], color + ':', linewidth = 3.0)\n",
    "draw(error, 'r','pred')\n",
    "plt.legend(fontsize=24)\n",
    "plt.grid(True)\n",
    "\n",
    "pdf_filename = f\"{folder}error_{datetime.now().strftime('%Y-%m-%d_%H-%M-%S')}.{fig_type}\"\n",
    "plt.savefig(pdf_filename)\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plotting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "300\n",
      "200\n",
      "300\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plotdata_pred = preds\n",
    "x = plotdata_pred\n",
    "xx = m_x.inverse_transform(tt_set_x.cpu().numpy()[:config['window_len'],0].reshape(-1, 1)).flatten() #反归一化\n",
    "# xx = tt_set_x.numpy()[:config['window_len'],0]\n",
    "t = np.array(list(range(0,len(x))))\n",
    "\n",
    "print(x.size)\n",
    "print(xx.size)\n",
    "print(t.size)\n",
    "\n",
    "# 创建一个散点图\n",
    "plt.figure(figsize=(10, 6))\n",
    "# plt.scatter(t,xx,label='true')\n",
    "plt.scatter(t,x,label='pred')\n",
    "plt.legend()  # 显示图例\n",
    "plt.xlabel('Time')\n",
    "plt.ylabel('Pos')\n",
    "plt.grid(True)\n",
    "plt.savefig('plot.png')  # 保存为文件\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
